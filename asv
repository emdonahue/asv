#!/bin/zsh

#TODO Throw error on invalid flags
#TODO Convert flags to new help format
#TODO Add -f field selection to update
#TODO Normalize all commands to take stdin or else manually parse flags for unix tools and pass them through to allow for uniform syntax
#TODO Insert column name parsing into all commands where it makes sense

set -o errexit
set -o pipefail
if [[ "${TRACE-0}" == "1" ]]; then set -o xtrace; fi

export LC_COLLATE=C #Selects the locale for determining sort order of dimensions.
unset c #Reserved variable for inline comments

local SOH=$'\001'
local STX=$'\002'
local GS=$'\035'
local RS='\0'
local FS=$'\036'
local US=$'\037'

asvawk() { #Accepts program as last argument and input file on stdin
    awk -v"OFS=$FS" -v"ORS=$RS" -v"FS=$FS" -v"RS=$RS" -f <(echo '1==NR {for (i=1;i<=NF;i++) { COLS[i]=i; COLS[$i]=i}}') -f <(echo "${${@}[-1]}") "${${@}[@]:0:-1}"
}

readheader() {
    read -rd$'\0' line
    echo -n "$line$RS"
}

rows() {
    readheader
    "$@"
}

rowawk() {    
    rows asvawk "$@"
}

writeheader() {
    local IFS="$FS"
    echo -n "$*$RS"
}

CMD="$1"
[[ $# -ne 0 ]] && shift
case "$CMD" in
    asv2tsv) #[ASV]; Converts ASV into a tsv.
	< "${1:-/dev/fd/0}" tr "$RS$FS" '\n\t'
	;;

    awk) #[OPTION]...; Runs awk on the rows of the asv on stdin.
	rowawk "$@"
	;;

    check) #[ASV]; Checks the integrity of the ASV in terms of column count and datatype consistency and presence of nulls.
	zparseopts -F -D t=TYPE ${c#; Turns off type checking}
	
	awk -v"T=${#TYPE}" -v"FS=$FS" -v"RS=$RS" 'NR==1 {split($0,names,FS); N=NF} 1<NR {if (N!=NF) {print "Row " (NR-1) " - Fields: " NF ", Expected: " N; e=1}; for (i=0;i<=NF;i++) {if ($i=="") {printf("Row %d Column %d (%s) is null\n",NR-1,i,names[i])} else {if (types[i]) {if (types[i]!=typeof($i) && !T) printf("Row %d Column %d (%s) - Type: %s, Expected: %s\n",NR-1,i,names[i],typeof($i),types[i])} else types[i]=typeof($i)}}} END {exit e}' "${1:--}" 1>&2
	;;

    count) #FIELD[,FIELD]... [ASV]; Aggregates and counts the rows grouped by FIELD ids.
	"$0" group "$@" | "$0" cut -f1 | "$0" uniq -c | asvawk -vFS='[[:space:]]+' '1==NR {print $1,"count"} 1<NR {print $3,$2}'
	;;
    
    cut) #[OPTION]...; Acts like unix cut on the asv using field names or ids.
	cut -zd"$FS" "$@"
	;;

    head) #N [ASV]; Prints the first N rows.
	< "${2:-/dev/fd/0}" rows head -zn"$1"
	;;
    
    header) #HEADER...; Sets the headers for the asv supplied on stdin to the list of HEADERS.
	writeheader "$@"
	tail -z -n+2
	;;

    --help|-h|help) #[SUBCOMMAND]; Prints help text for SUBCOMMAND. If SUBCOMMAND omitted, prints list of subcommands.
	[[ $# -eq 0 ]] && echo 'asv - ASCII-Separated Values\nTabular text data manipulation using ASCII control characters as table structure. \nUsage: asv SUBCOMMAND [ARGUMENTS...]\n\nSubcommands:'
	    sed -nE '/\s*'"$1"'\)\s#/'"${1:+,/^\s*;;\s*$/}"'{s/^[[:space:]]*([-|[:alnum:]]+)\)\s#([^;]*); (.*)/'"${${1-\t}:#$1}"'\1 \2\t\3/p; s/.*(\w+)[-+:]*=\w+ \$\{c#(.*); (.*)\}.*/\t-\1 \2\t\3/p}' "$0"
	;;

    group) #FIELD[,FIELD]... [ASV]; Creates an grouped column at position 1 by concatenating and sorting values from the comma-separated list of fields. The fields are then removed from the table until it is unjoined. Useful for aggregate functions and multi-column joins.
	< "${2:-/dev/fd/0}" asvawk '{$(NF+1)=$'"${1//,/\"\035\"$}"'; print}' | "$0" project -v "$1" | asvawk '{for (i=NF;1<=i;i--) {$(i+1)=$i}; $1=$NF; NF--; print}' | "$0" sort -k1,1
	;;
    
    join) #[OPTION]... FILE1 FILE2; Runs unix join on the two files.
	join -zt"$FS" --header "$@"
	;;

    less) #[ASV]; Lightly formats the table and pipes it to less for inspection.
	<"${1:-/dev/fd/0}" "$0" asv2tsv | less -S
	;;

    plot) #[ASV]...; Plots the data with gnuplot.
	zparseopts -F -D c=CATEGORICAL ${c#; Uses column 1 as the x domain instead of the row number}\
		   d=DOMAIN ${c#; Uses column 1 as the x domain instead of the row number}\
		   s:=SETTINGS ${c#SET; Inserts block of semicolon-separated SET statements into the gnuplot program. Input is pasted verbatim into the preamble of the gnuplot program, so "set" must be written out.}		   
	local DATA=$(mktemp --suffix=.asv)
	trap "rm -f $DATA" EXIT
	local GPLOT=$(awk -vRS="$RS" -vFS="$FS" -vDATA="$DATA" -vDOMAIN=${#DOMAIN} -vCATEGORICAL=${#CATEGORICAL} -vgp="\"$DATA\" index %s using %s:%s%s" 'BEGINFILE {print "\n" > DATA} {$1=$1} 1==FNR {for (i=1;i<=NF;i++) printf("\"%s\"%s",$i,i==NF?ORS:OFS) > DATA; for (i=1+DOMAIN+CATEGORICAL;i<=NF;i++) printf("%s"gp,2+DOMAIN+CATEGORICAL==NR+i?"":",",ARGIND-1,DOMAIN,i,CATEGORICAL?":xtic("(DOMAIN+1)")":"")} 1<FNR {for (i=1;i<=NF;i++) $i=$i?$i:"."; print > DATA}' "$@")
	gnuplot -p -e "set style data linespoints; set key autotitle columnheader; ${SETTINGS[2]}; plot $GPLOT"	
	;;
    
    project) #[OPTIONS]... FIELD[,FIELD]...; Similar to cut, but limited to comma syntax and allows column rearrangement and column names in addition to indices.
	zparseopts -F -D v=INVERT ${c#; Inverts projection. Equivalent to unix cut --complement.}
	asvawk -vFIELDS="$1" -vV="${#INVERT}" '1==NR {split(FIELDS,FIDS,","); for (i in FIDS) {FIDS[i]=COLS[FIDS[i]]}; if (V) {for (i in FIDS) {inv[FIDS[i]]=FIDS[i]}; delete FIDS; for (i=1;i<=NF;i++) {if (!(i in inv)) {FIDS[length(FIDS)+1]=i}}}} {for (i in FIDS) {printf("%s%s",$(FIDS[i]),i==length(FIDS)?RS:FS)}}'
	;;
	
    rows) #COMMAND; Prints the header of the asv on stdin then executes an arbitrary unix COMMAND with the rows on stdin.
	rows "$@"
	;;

    schema) #ASV; Prints the table headers along with their indices for use in other commands.
	{echo -n "id${FS}column$RS"; asvawk '{for (i=1;i<=NF;i++) print i,$i; exit}' < "${1:-/dev/fd/0}"} | "$0" asv2tsv
	;;

    select) #[OPTION]... REGEX [ASV]; Selects rows in which a value matches REGEX.
	      zparseopts -F -D i=IGNORECASE ${c#; ; Ignores case}\
			 f:=FIELD ${c#; FIELD; Match only in field number FIELD}\
			 v=INVERT ${c#; Inverts match}
	< "${2:-/dev/fd/0}" rowawk -vR="$1" -vI="${#IGNORECASE}" -vF="${FIELD[2]}" -vV="${#INVERT}" 'BEGIN {IGNORECASE=I}  {for (i=1;i<=NF;i++) {if (F && F!=i) continue; if (match($i,R)) {if (V) next; print; next}}; if (V) print}'
	;;

    size) #ASV; Counts the rows in ASV.
	awk -v"FS=$FS" -v"RS=$RS" 'END {print NR-1}' "${1:--}"
	;;
    
    sort) #[OPTION]...; Runs unix sort on just the rows of the asv supplied on stdin.
	rows sort -zt"$FS" "$@"
	;;

    ungroup) #[ASV]; Ungroups the group column and restores the multiple columns from which it was computed. Use after multi-column joins or aggregates to restore a complete table.
	< "${1:-/dev/fd/0}" tr "$GS" "$FS"
	;;
    
    uniq) #[OPTION]... [ASV]; Performs unix uniq on the asv on stdin.
	rows uniq -z "$@"
	;;
    
    update) #PATTERN REPLACEMENT [ASV]; Replaces regex PATTERN with REPLACEMENT, which may use back references.
	< "${3:-/dev/fd/0}" rowawk -vR="$1" -vs="${(q)2}" '{for (i=1;i<=NF;i++) $i=gensub(R,s,"g",$i); print}'
	;;

    tail) #N [ASV]; Prints the last N rows.
	< "${2:-/dev/fd/0}" rows tail -zn"$1"
	;;
    
    tokenize) #TOKENS [TOKENS...]; Converts each whitespace-separated TOKENS file into a token table and concatenates them all.
	zparseopts -F -D l=FNAMES ${c#; Adds column representing filename in which token was found}
	echo -n ${FNAMES[1]:+"filename$FS"}
	echo -n "token$RS"
	awk -vFNAMES="${#FNAMES}" -v'RS=[[:space:][:cntrl:]]+' -v"OFS=$FS" -v"ORS=$RS" '$0!="" {printf("%s%s"ORS, FNAMES ? FILENAME OFS : "", $0)}' "$@"
	;;

    tsv2asv) #[HEADER...]; Converts TSV on stdin into an asv table using HEADERS as the columns. If no HEADERS are supplied, the first row of TSV is used as the header.
	[[ $# -ne 0 ]] && writeheader "$@"
	tr '\n\t' "$RS$FS"
	;;
    
    *)
	if [[ -z "$CMD" ]]; then
	    "$0" help
	else
	    "$0" help 1>&2
	    exit 1
	fi
	;;
esac
