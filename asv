#!/bin/zsh

#TODO add -f field selection to substitute
#TODO normalize all commands to take stdin or else manually parse flags to allow for uniform syntax

set -o errexit
set -o pipefail
if [[ "${TRACE-0}" == "1" ]]; then set -o xtrace; fi

export LC_COLLATE="${LC_COLLATE:-C}" #Selects the locale for determining sort order of dimensions.

local SOH=$'\001'
local STX=$'\002'
local GS=$'\035'
local RS='\0'
local FS=$'\036'
local US=$'\037'

#Accepts program as last argument and input file on stdin
asvawk() {
    #1==NR {for (i=1;i<=NF;i++) { COLS[i]=i; COLS[$i]=i}}
    #-f <(echo 'BEGIN {xxx=2}')
    awk -v"OFS=$FS" -v"ORS=$RS" -v"FS=$FS" -v"RS=$RS" -f <(echo '1==NR {for (i=1;i<=NF;i++) { COLS[i]=i; COLS[$i]=i}}') -f <(echo "${${@}[-1]}") "${${@}[@]:0:-1}"
}

readheader() {
    read -rd$'\0' line
    echo -n "$line$RS"
}

rows() {
    readheader
    "$@"
}

rowawk() {    
    rows asvawk "$@"
}

echoheader() {
    local IFS="$FS"
    echo -n "$*$RS"
}

CMD="$1"
[[ $# -ne 0 ]] && shift
case "$CMD" in
    asv2tsv) #[ASV]; Converts ASV into a tsv.
	< "${1:-/dev/fd/0}" tr "$RS$FS" '\n\t'
	;;

    awk) #[OPTION]...; Runs awk on the rows of the asv on stdin.
	rowawk "$@"
	;;

    check) #[ASV]; Checks the integrity of the ASV in terms of column count and datatype consistency and presence of nulls.
	zparseopts -A opts -E -D t
	local TYPE=${+opts[-t]} #; Turns off type checking
	
	awk -v"T=$TYPE" -v"FS=$FS" -v"RS=$RS" 'NR==1 {split($0,names,FS); N=NF} 1<NR {if (N!=NF) {print "Row " (NR-1) " - Fields: " NF ", Expected: " N; e=1}; for (i=0;i<=NF;i++) {if ($i=="") {printf("Row %d Column %d (%s) is null\n",NR-1,i,names[i])} else {if (types[i]) {if (types[i]!=typeof($i) && !T) printf("Row %d Column %d (%s) - Type: %s, Expected: %s\n",NR-1,i,names[i],typeof($i),types[i])} else types[i]=typeof($i)}}} END {exit e}' "${1:--}" 1>&2
	;;

    count) #FIELD[,FIELD]... [ASV]; Aggregates and counts the rows grouped by FIELD ids.
	"$0" group "$@" | "$0" cut -f1 | "$0" uniq -c | asvawk -vFS='[[:space:]]+' '1==NR {print $1,"count"} 1<NR {print $3,$2}'
	;;
    
    cut) #[OPTION]...; Acts like unix cut on the asv using field names or ids.
	cut -zd"$FS" "$@"
	;;

    head) #N [ASV]; Prints the first N rows.
	< "${2:-/dev/fd/0}" rows head -zn"$1"
	;;
    
    header) #HEADER...; Sets the headers for the asv supplied on stdin to the list of HEADERS.
	echoheader "$@"
	tail -z -n+2
	;;

    group) #FIELD[,FIELD]... [ASV]; Creates an grouped column at position 1 by concatenating and sorting values from the comma-separated list of fields. The fields are then removed from the table until it is unjoined. Useful for aggregate functions and multi-column joins.
	< "${2:-/dev/fd/0}" asvawk '{$(NF+1)=$'"${1//,/\"\035\"$}"'; print}' | "$0" project -v "$1" | asvawk '{for (i=NF;1<=i;i--) {$(i+1)=$i}; $1=$NF; NF--; print}' | "$0" sort -k1,1
	;;
    
    join) #[OPTION]... FILE1 FILE2; Runs unix join on the two files.
	join -zt"$FS" --header "$@"
	;;

    less) #[ASV]; Lightly formats the table and pipes it to less for inspection.
	<"${1:-/dev/fd/0}" "$0" asv2tsv | less -S
	;;

    plot) #[ASV]...; Plots the data with gnuplot.
	zparseopts -A opts -E -D d
	local DOMAIN=${+opts[-d]} #; Turns off type checking
	#set style data linespoints
	#set key autotitle columnheader
	#-d[column] uses this column as domain. default to 1 for now to simplify iteration
	#header address with (column("header"))
	#-c for categorical
	#insert periods for nulls
	DATA=$(mktemp --suffix=.asv)
	trap "rm -f $DATA" EXIT
	echo 'a b c\n10 2 3\n20 4 9\n30 16 27' > $DATA
	gnuplot -p -e "set style data linespoints; set key autotitle columnheader; plot for [i=$((DOMAIN+1)):*] \"$DATA\" using ${DOMAIN+1:}i"
	
	;;
    
    project) #[OPTIONS]... FIELD[,FIELD]...; Similar to cut, but limited to comma syntax and allows column rearrangement and column names in addition to indices.
	zparseopts -A opts -E -D v
	local INVERT=${+opts[-v]} #; Inverts projection. Equivalent to unix cut --complement
	asvawk -vFIELDS="$1" -vV="$INVERT" '1==NR {split(FIELDS,FIDS,","); for (i in FIDS) {FIDS[i]=COLS[FIDS[i]]}; if (V) {for (i in FIDS) {inv[FIDS[i]]=FIDS[i]}; delete FIDS; for (i=1;i<=NF;i++) {if (!(i in inv)) {FIDS[length(FIDS)+1]=i}}}} {for (i in FIDS) {printf("%s%s",$(FIDS[i]),i==length(FIDS)?RS:FS)}}'
	;;
	
    rows) #COMMAND; Prints the header of the asv on stdin then executes an arbitrary unix COMMAND with the rows on stdin.
	rows "$@"
	;;

    schema) #ASV; Prints the table headers along with their indices for use in other commands.
	{echo -n "id${FS}column$RS"; asvawk '{for (i=1;i<=NF;i++) print i,$i; exit}' < "${1:-/dev/fd/0}"} | "$0" asv2tsv
	;;

    select) #[OPTION]... REGEX [ASV]; Selects rows in which a value matches REGEX.
	zparseopts -A opts -E -D i v f:
	local IGNORECASE=${+opts[-i]} #; Ignores case
	local FIELD="${opts[-f]:-0}" #FIELD; Match only in field number FIELD.
	local INVERTMATCH=${+opts[-v]} #; Inverts match
	< "${2:-/dev/fd/0}" rowawk -vR="$1" -vI="$IGNORECASE" -vF="$FIELD" -vV="$INVERTMATCH" 'BEGIN {IGNORECASE=I}  {for (i=1;i<=NF;i++) {if (F && F!=i) continue; if (match($i,R)) {if (V) next; print; next}}; if (V) print}'
	;;

    size) #ASV; Counts the rows in ASV.
	awk -v"FS=$FS" -v"RS=$RS" 'END {print NR-1}' "${1:--}"
	;;
    
    sort) #[OPTION]...; Runs unix sort on just the rows of the asv supplied on stdin.
	rows sort -zt"$FS" "$@"
	;;

    ungroup) #[ASV]; Ungroups the group column and restores the multiple columns from which it was computed. Use after multi-column joins or aggregates to restore a complete table.
	< "${1:-/dev/fd/0}" tr "$GS" "$FS"
	;;
    
    uniq) #[OPTION]... [ASV]; Performs unix uniq on the asv on stdin.
	rows uniq -z "$@"
	;;
    
    update) #PATTERN REPLACEMENT [ASV]; Replaces regex PATTERN with REPLACEMENT, which may use back references.
	< "${3:-/dev/fd/0}" rowawk -vR="$1" -vs="${2//\\/\\\\}" '{for (i=1;i<=NF;i++) $i=gensub(R,s,"g",$i); print}'
	;;

    tail) #N [ASV]; Prints the last N rows.
	< "${2:-/dev/fd/0}" rows tail -zn"$1"
	;;
    
    tokenize) #TOKENS [TOKENS...]; Converts each whitespace-separated TOKENS file into a token table and concatenates them all.
	zparseopts -A opts -E -D l
	local FNAMES=${+opts[-l]} #; Adds column representing filename in which token was found.

	[[ "$FNAMES" -eq 1 ]] && echo -n "filename$FS"
	echo -n "token$RS"
	awk -vFNAMES="$FNAMES" -v'RS=[[:space:][:cntrl:]]+' -v"OFS=$FS" -v"ORS=$RS" '$0!="" {printf("%s%s"ORS, FNAMES ? FILENAME OFS : "", $0)}' "$@"
	;;

    tsv2asv) #[HEADER...]; Converts TSV on stdin into an asv table using HEADERS as the columns. If no HEADERS are supplied, the first row of TSV is used as the header.
	[[ $# -ne 0 ]] && echoheader "$@"
	tr '\n\t' "$RS$FS"
	;;

    --help|-h|help) #[SUBCOMMAND]; Prints help text for SUBCOMMAND. If SUBCOMMAND omitted, prints list of subcommands.
	    [[ $# -eq 0 ]] && echo 'asv - ASCII-Separated Values\nTabular text data manipulation using ASCII control characters as table structure. \nUsage: asv SUBCOMMAND [ARGUMENTS...]\n\nSubcommands:'
	    grep -E -- "${1:-\\w+}\)\s#" "$0" | sed -E -- "s/^[[:space:]]*([-|[:alnum:]]+)\)\s#([^;]*); (.*)/\1 \2\t\3/" | sed $((${+1}+1))',$ s/^[[:space:]]*/\t/'
	    [[ $# -ne 0 ]] && sed -nE "/\s*$1\)\s#/,/^\s*;;\s*$/ s/.*opts\[([-[:alnum:]]+)\].*#(.*); (.*)/\t\1 \2\t\3/p" "$0" 
	    ;;
    *)
	if [[ -z "$CMD" ]]; then
	    "$0" help
	else
	    "$0" help 1>&2
	    exit 1
	fi
	;;
esac
